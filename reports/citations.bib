
@inproceedings{fujita_basic_2016,
	address = {Anaheim, CA, USA},
	title = {Basic {Investigation} on a {Robust} and {Practical} {Plant} {Diagnostic} {System}},
	isbn = {9781509061679},
	url = {http://ieeexplore.ieee.org/document/7838282/},
	doi = {10.1109/ICMLA.2016.0178},
	urldate = {2020-01-02},
	booktitle = {2016 15th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Fujita, Erika and Kawasaki, Yusuke and Uga, Hiroyuki and Kagiwada, Satoshi and Iyatomi, Hitoshi},
	month = dec,
	year = {2016},
	pages = {989--992}
}

@article{naik_real-time_2017,
	title = {A real-time phenotyping framework using machine learning for plant stress severity rating in soybean},
	volume = {13},
	issn = {1746-4811},
	url = {https://doi.org/10.1186/s13007-017-0173-7},
	doi = {10.1186/s13007-017-0173-7},
	abstract = {Phenotyping is a critical component of plant research. Accurate and precise trait collection, when integrated with genetic tools, can greatly accelerate the rate of genetic gain in crop improvement. However, efficient and automatic phenotyping of traits across large populations is a challenge; which is further exacerbated by the necessity of sampling multiple environments and growing replicated trials. A promising approach is to leverage current advances in imaging technology, data analytics and machine learning to enable automated and fast phenotyping and subsequent decision support. In this context, the workflow for phenotyping (image capture → data storage and curation → trait extraction → machine learning/classification → models/apps for decision support) has to be carefully designed and efficiently executed to minimize resource usage and maximize utility. We illustrate such an end-to-end phenotyping workflow for the case of plant stress severity phenotyping in soybean, with a specific focus on the rapid and automatic assessment of iron deficiency chlorosis (IDC) severity on thousands of field plots. We showcase this analytics framework by extracting IDC features from a set of {\textasciitilde}4500 unique canopies representing a diverse germplasm base that have different levels of IDC, and subsequently training a variety of classification models to predict plant stress severity. The best classifier is then deployed as a smartphone app for rapid and real time severity rating in the field.},
	number = {1},
	urldate = {2020-01-02},
	journal = {Plant Methods},
	author = {Naik, Hsiang Sing and Zhang, Jiaoping and Lofquist, Alec and Assefa, Teshale and Sarkar, Soumik and Ackerman, David and Singh, Arti and Singh, Asheesh K. and Ganapathysubramanian, Baskar},
	month = apr,
	year = {2017},
	pages = {23}
}

@misc{sladojevic_deep_2016,
	type = {Research article},
	title = {Deep {Neural} {Networks} {Based} {Recognition} of {Plant} {Diseases} by {Leaf} {Image} {Classification}},
	url = {https://www.hindawi.com/journals/cin/2016/3289801/},
	abstract = {The latest generation of convolutional neural networks (CNNs) has achieved impressive results in the field of image classification. This paper is concerned with a new approach to the development of plant disease recognition model, based on leaf image classification, by the use of deep convolutional networks. Novel way of training and the methodology used facilitate a quick and easy system implementation in practice. The developed model is able to recognize 13 different types of plant diseases out of healthy leaves, with the ability to distinguish plant leaves from their surroundings. According to our knowledge, this method for plant disease recognition has been proposed for the first time. All essential steps required for implementing this disease recognition model are fully described throughout the paper, starting from gathering images in order to create a database, assessed by agricultural experts. Caffe, a deep learning framework developed by Berkley Vision and Learning Centre, was used to perform the deep CNN training. The experimental results on the developed model achieved precision between 91\% and 98\%, for separate class tests, on average 96.3\%.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Computational Intelligence and Neuroscience},
	author = {Sladojevic, Srdjan and Arsenovic, Marko and Anderla, Andras and Culibrk, Dubravko and Stefanovic, Darko},
	year = {2016},
	doi = {10.1155/2016/3289801}
}

@misc{toda_how_2019,
	type = {Research article},
	title = {How {Convolutional} {Neural} {Networks} {Diagnose} {Plant} {Disease}},
	url = {https://spj.sciencemag.org/plantphenomics/2019/9237136/},
	abstract = {Deep learning with convolutional neural networks (CNNs) has achieved great success in the classification of various plant diseases. However, a limited number of studies have elucidated the process of inference, leaving it as an untouchable black box. Revealing the CNN to extract the learned feature as an interpretable form not only ensures its reliability but also enables the validation of the model authenticity and the training dataset by human intervention. In this study, a variety of neuron-wise and layer-wise visualization methods were applied using a CNN, trained with a publicly available plant disease image dataset. We showed that neural networks can capture the colors and textures of lesions specific to respective diseases upon diagnosis, which resembles human decision-making. While several visualization methods were used as they are, others had to be optimized to target a specific layer that fully captures the features to generate consequential outputs. Moreover, by interpreting the generated attention maps, we identified several layers that were not contributing to inference and removed such layers inside the network, decreasing the number of parameters by 75\&amp;\#x25; without affecting the classification accuracy. The results provide an impetus for the CNN black box users in the field of plant science to better understand the diagnosis process and lead to further efficient use of deep learning for plant disease diagnosis.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Plant Phenomics},
	author = {Toda, Yosuke and Okura, Fumio},
	year = {2019},
	doi = {10.34133/2019/9237136}
}

@article{fuentes_robust_2017,
	title = {A {Robust} {Deep}-{Learning}-{Based} {Detector} for {Real}-{Time} {Tomato} {Plant} {Diseases} and {Pests} {Recognition}},
	volume = {17},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/17/9/2022},
	doi = {10.3390/s17092022},
	abstract = {Plant Diseases and Pests are a major challenge in the agriculture sector. An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses. Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems. In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions. Our goal is to find the more suitable deep-learning architecture for our task. Therefore, we consider three main families of detectors: Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called “deep learning meta-architectures”. We combine each of these meta-architectures with “deep feature extractors” such as VGG net and Residual Network (ResNet). We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training. We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant. Experimental results show that our proposed system can effectively recognize nine different types of diseases and pests, with the ability to deal with complex scenarios from a plant’s surrounding area.},
	language = {en},
	number = {9},
	urldate = {2020-01-02},
	journal = {Sensors},
	author = {Fuentes, Alvaro and Yoon, Sook and Kim, Sang Cheol and Park, Dong Sun},
	month = sep,
	year = {2017},
	keywords = {plant disease, pest, deep convolutional neural networks, real-time processing, detection},
	pages = {2022}
}

@inproceedings{tripathi_recent_2016,
	address = {Pune, India},
	title = {Recent machine learning based approaches for disease detection and classification of agricultural products},
	isbn = {9781509032914},
	url = {http://ieeexplore.ieee.org/document/7860043/},
	doi = {10.1109/ICCUBEA.2016.7860043},
	urldate = {2020-01-02},
	booktitle = {2016 {International} {Conference} on {Computing} {Communication} {Control} and automation ({ICCUBEA})},
	publisher = {IEEE},
	author = {Tripathi, Mukesh Kumar and Maktedar, Dhananjay D.},
	month = aug,
	year = {2016},
	pages = {1--6}
}

@article{liakos_machine_2018,
	title = {Machine {Learning} in {Agriculture}: {A} {Review}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Machine {Learning} in {Agriculture}},
	url = {https://www.mdpi.com/1424-8220/18/8/2674},
	doi = {10.3390/s18082674},
	abstract = {Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.},
	language = {en},
	number = {8},
	urldate = {2020-01-02},
	journal = {Sensors},
	author = {Liakos, Konstantinos G. and Busato, Patrizia and Moshou, Dimitrios and Pearson, Simon and Bochtis, Dionysis},
	month = aug,
	year = {2018},
	keywords = {crop management, water management, soil management, livestock management, artificial intelligence, planning, precision agriculture},
	pages = {2674}
}

@article{al_hiary_fast_2011,
	title = {Fast and {Accurate} {Detection} and {Classification} of {Plant} {Diseases}},
	volume = {17},
	issn = {09758887},
	url = {http://www.ijcaonline.org/volume17/number1/pxc3872754.pdf},
	doi = {10.5120/2183-2754},
	number = {1},
	urldate = {2020-01-03},
	journal = {International Journal of Computer Applications},
	author = {Al Hiary, H. and Bani Ahmad, S. and Reyalat, M. and Braik, M. and ALRahamneh, Z.},
	month = mar,
	year = {2011},
	pages = {31--38}
}


@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=3098997.3065386},
	doi = {10.1145/3065386},
	language = {en},
	number = {6},
	urldate = {2020-01-27},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = may,
	year = {2017},
	pages = {84--90}
}


@misc{noauthor_late_2009,
	title = {late blight ({Phytophthora} infestans )},
	url = {http://www.invasive.org/browse/detail.cfm?imgnum=1571049},
	abstract = {Image 1571049 is of late blight (Phytophthora infestans ) symptoms on potato. It is by Gerald Holmes at California Polytechnic State University at San Luis Obispo.},
	language = {en},
	urldate = {2020-02-09},
	journal = {Invasive.Org},
	month = oct,
	year = {2009}
}

@misc{noauthor_strawberry_2008,
	title = {strawberry leaf spot ({Mycosphaerella} fragariae )},
	url = {http://www.invasive.org/browse/detail.cfm?imgnum=5365398},
	abstract = {Image 5365398 is of strawberry leaf spot (Mycosphaerella fragariae ) symptoms on strawberry. It is by Curtis Swift at Colorado State University. Strawberry leaf showing symptoms of infection with leaf spot (Mycosphaerella fragariae).},
	language = {en},
	urldate = {2020-02-09},
	journal = {Invasive.Org},
	month = apr,
	year = {2008}
}

@misc{noauthor_leaf_2013,
	title = {leaf spot ({Stemphylium} spp. )},
	url = {http://www.invasive.org/browse/detail.cfm?imgnum=5503914},
	abstract = {Image 5503914 is of leaf spot (Stemphylium spp. ) symptoms on garden tomato. It is by Bruce Watt at University of Maine. Infected leaf},
	language = {en},
	urldate = {2020-02-09},
	journal = {Invasive.Org},
	month = oct,
	year = {2013}
}

@misc{noauthor_septoria_2011,
	title = {Septoria leaf spot ({Septoria} helianthi )},
	url = {http://www.invasive.org/browse/detail.cfm?imgnum=5430722},
	abstract = {Image 5430722 is of Septoria leaf spot (Septoria helianthi ) symptoms on common sunflower. It is by Nancy Gregory at University of Delaware.},
	language = {en},
	urldate = {2020-02-09},
	journal = {Invasive.Org},
	month = feb,
	year = {2011}
}

@misc{noauthor_common_2012,
	title = {common corn rust ({Puccinia} sorghi )},
	url = {http://www.invasive.org/browse/detail.cfm?imgnum=5465560},
	abstract = {Image 5465560 is of common corn rust (Puccinia sorghi ) symptoms on corn. It is by Daren Mueller at Iowa State University.},
	language = {en},
	urldate = {2020-02-09},
	journal = {Invasive.Org},
	month = mar,
	year = {2012}
}


@inproceedings{albawi_understanding_2017,
	title = {Understanding of a convolutional neural network},
	doi = {10.1109/ICEngTechnol.2017.8308186},
	abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
	booktitle = {2017 {International} {Conference} on {Engineering} and {Technology} ({ICET})},
	author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
	month = aug,
	year = {2017},
	note = {ISSN: null},
	keywords = {computer vision, feedforward neural nets, image classification, learning (artificial intelligence), natural language processing, fully-connected layers, convolutional connected layers, nonlinearity layer, multiple layers, matrixes called convolution, mathematical linear operation, classical methods performance, deeper hidden layers, multilayers, Artificial Neural Networks, Deep Neural Network, term Deep Learning, convolutional neural network, artificial neural network, largest image classification data, image data, CNN, pooling, Convolution, Neurons, Convolutional neural networks, Feature extraction, Image edge detection, machine learning, artificial neural networks, deep learning, convolutional neural networks, computer vision, Image recognition},
	pages = {1--6}
}

@article{koushik_understanding_2016,
	title = {Understanding {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1605.09081},
	abstract = {Convoulutional Neural Networks (CNNs) exhibit extraordinary performance on a variety of machine learning tasks. However, their mathematical properties and behavior are quite poorly understood. There is some work, in the form of a framework, for analyzing the operations that they perform. The goal of this project is to present key results from this theory, and provide intuition for why CNNs work.},
	urldate = {2020-02-09},
	journal = {arXiv:1605.09081 [stat]},
	author = {Koushik, Jayanth},
	month = may,
	year = {2016},
	note = {arXiv: 1605.09081},
	keywords = {Statistics - Other Statistics}
}

@article{oshea_introduction_2015,
	title = {An {Introduction} to {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.08458},
	abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
	urldate = {2020-02-09},
	journal = {arXiv:1511.08458 [cs]},
	author = {O'Shea, Keiron and Nash, Ryan},
	month = dec,
	year = {2015},
	note = {arXiv: 1511.08458},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}
