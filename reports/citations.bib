
@inproceedings{fujita_basic_2016,
	address = {Anaheim, CA, USA},
	title = {Basic {Investigation} on a {Robust} and {Practical} {Plant} {Diagnostic} {System}},
	isbn = {9781509061679},
	url = {http://ieeexplore.ieee.org/document/7838282/},
	doi = {10.1109/ICMLA.2016.0178},
	urldate = {2020-01-02},
	booktitle = {2016 15th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Fujita, Erika and Kawasaki, Yusuke and Uga, Hiroyuki and Kagiwada, Satoshi and Iyatomi, Hitoshi},
	month = dec,
	year = {2016},
	pages = {989--992}
}

@article{naik_real-time_2017,
	title = {A real-time phenotyping framework using machine learning for plant stress severity rating in soybean},
	volume = {13},
	issn = {1746-4811},
	url = {https://doi.org/10.1186/s13007-017-0173-7},
	doi = {10.1186/s13007-017-0173-7},
	abstract = {Phenotyping is a critical component of plant research. Accurate and precise trait collection, when integrated with genetic tools, can greatly accelerate the rate of genetic gain in crop improvement. However, efficient and automatic phenotyping of traits across large populations is a challenge; which is further exacerbated by the necessity of sampling multiple environments and growing replicated trials. A promising approach is to leverage current advances in imaging technology, data analytics and machine learning to enable automated and fast phenotyping and subsequent decision support. In this context, the workflow for phenotyping (image capture → data storage and curation → trait extraction → machine learning/classification → models/apps for decision support) has to be carefully designed and efficiently executed to minimize resource usage and maximize utility. We illustrate such an end-to-end phenotyping workflow for the case of plant stress severity phenotyping in soybean, with a specific focus on the rapid and automatic assessment of iron deficiency chlorosis (IDC) severity on thousands of field plots. We showcase this analytics framework by extracting IDC features from a set of {\textasciitilde}4500 unique canopies representing a diverse germplasm base that have different levels of IDC, and subsequently training a variety of classification models to predict plant stress severity. The best classifier is then deployed as a smartphone app for rapid and real time severity rating in the field.},
	number = {1},
	urldate = {2020-01-02},
	journal = {Plant Methods},
	author = {Naik, Hsiang Sing and Zhang, Jiaoping and Lofquist, Alec and Assefa, Teshale and Sarkar, Soumik and Ackerman, David and Singh, Arti and Singh, Asheesh K. and Ganapathysubramanian, Baskar},
	month = apr,
	year = {2017},
	pages = {23}
}

@misc{sladojevic_deep_2016,
	type = {Research article},
	title = {Deep {Neural} {Networks} {Based} {Recognition} of {Plant} {Diseases} by {Leaf} {Image} {Classification}},
	url = {https://www.hindawi.com/journals/cin/2016/3289801/},
	abstract = {The latest generation of convolutional neural networks (CNNs) has achieved impressive results in the field of image classification. This paper is concerned with a new approach to the development of plant disease recognition model, based on leaf image classification, by the use of deep convolutional networks. Novel way of training and the methodology used facilitate a quick and easy system implementation in practice. The developed model is able to recognize 13 different types of plant diseases out of healthy leaves, with the ability to distinguish plant leaves from their surroundings. According to our knowledge, this method for plant disease recognition has been proposed for the first time. All essential steps required for implementing this disease recognition model are fully described throughout the paper, starting from gathering images in order to create a database, assessed by agricultural experts. Caffe, a deep learning framework developed by Berkley Vision and Learning Centre, was used to perform the deep CNN training. The experimental results on the developed model achieved precision between 91\% and 98\%, for separate class tests, on average 96.3\%.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Computational Intelligence and Neuroscience},
	author = {Sladojevic, Srdjan and Arsenovic, Marko and Anderla, Andras and Culibrk, Dubravko and Stefanovic, Darko},
	year = {2016},
	doi = {10.1155/2016/3289801}
}

@misc{toda_how_2019,
	type = {Research article},
	title = {How {Convolutional} {Neural} {Networks} {Diagnose} {Plant} {Disease}},
	url = {https://spj.sciencemag.org/plantphenomics/2019/9237136/},
	abstract = {Deep learning with convolutional neural networks (CNNs) has achieved great success in the classification of various plant diseases. However, a limited number of studies have elucidated the process of inference, leaving it as an untouchable black box. Revealing the CNN to extract the learned feature as an interpretable form not only ensures its reliability but also enables the validation of the model authenticity and the training dataset by human intervention. In this study, a variety of neuron-wise and layer-wise visualization methods were applied using a CNN, trained with a publicly available plant disease image dataset. We showed that neural networks can capture the colors and textures of lesions specific to respective diseases upon diagnosis, which resembles human decision-making. While several visualization methods were used as they are, others had to be optimized to target a specific layer that fully captures the features to generate consequential outputs. Moreover, by interpreting the generated attention maps, we identified several layers that were not contributing to inference and removed such layers inside the network, decreasing the number of parameters by 75\&amp;\#x25; without affecting the classification accuracy. The results provide an impetus for the CNN black box users in the field of plant science to better understand the diagnosis process and lead to further efficient use of deep learning for plant disease diagnosis.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Plant Phenomics},
	author = {Toda, Yosuke and Okura, Fumio},
	year = {2019},
	doi = {10.34133/2019/9237136}
}

@article{fuentes_robust_2017,
	title = {A {Robust} {Deep}-{Learning}-{Based} {Detector} for {Real}-{Time} {Tomato} {Plant} {Diseases} and {Pests} {Recognition}},
	volume = {17},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/17/9/2022},
	doi = {10.3390/s17092022},
	abstract = {Plant Diseases and Pests are a major challenge in the agriculture sector. An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses. Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems. In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions. Our goal is to find the more suitable deep-learning architecture for our task. Therefore, we consider three main families of detectors: Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called “deep learning meta-architectures”. We combine each of these meta-architectures with “deep feature extractors” such as VGG net and Residual Network (ResNet). We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training. We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant. Experimental results show that our proposed system can effectively recognize nine different types of diseases and pests, with the ability to deal with complex scenarios from a plant’s surrounding area.},
	language = {en},
	number = {9},
	urldate = {2020-01-02},
	journal = {Sensors},
	author = {Fuentes, Alvaro and Yoon, Sook and Kim, Sang Cheol and Park, Dong Sun},
	month = sep,
	year = {2017},
	keywords = {plant disease, pest, deep convolutional neural networks, real-time processing, detection},
	pages = {2022}
}

@inproceedings{tripathi_recent_2016,
	address = {Pune, India},
	title = {Recent machine learning based approaches for disease detection and classification of agricultural products},
	isbn = {9781509032914},
	url = {http://ieeexplore.ieee.org/document/7860043/},
	doi = {10.1109/ICCUBEA.2016.7860043},
	urldate = {2020-01-02},
	booktitle = {2016 {International} {Conference} on {Computing} {Communication} {Control} and automation ({ICCUBEA})},
	publisher = {IEEE},
	author = {Tripathi, Mukesh Kumar and Maktedar, Dhananjay D.},
	month = aug,
	year = {2016},
	pages = {1--6}
}

@article{liakos_machine_2018,
	title = {Machine {Learning} in {Agriculture}: {A} {Review}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Machine {Learning} in {Agriculture}},
	url = {https://www.mdpi.com/1424-8220/18/8/2674},
	doi = {10.3390/s18082674},
	abstract = {Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.},
	language = {en},
	number = {8},
	urldate = {2020-01-02},
	journal = {Sensors},
	author = {Liakos, Konstantinos G. and Busato, Patrizia and Moshou, Dimitrios and Pearson, Simon and Bochtis, Dionysis},
	month = aug,
	year = {2018},
	keywords = {crop management, water management, soil management, livestock management, artificial intelligence, planning, precision agriculture},
	pages = {2674}
}

@article{al_hiary_fast_2011,
	title = {Fast and {Accurate} {Detection} and {Classification} of {Plant} {Diseases}},
	volume = {17},
	issn = {09758887},
	url = {http://www.ijcaonline.org/volume17/number1/pxc3872754.pdf},
	doi = {10.5120/2183-2754},
	number = {1},
	urldate = {2020-01-03},
	journal = {International Journal of Computer Applications},
	author = {Al Hiary, H. and Bani Ahmad, S. and Reyalat, M. and Braik, M. and ALRahamneh, Z.},
	month = mar,
	year = {2011},
	pages = {31--38}
}